{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba80925",
   "metadata": {},
   "source": [
    "# AWS Machine Learning 목적별 가속기 튜토리얼\n",
    "## [AWS Trainium](https://aws.amazon.com/machine-learning/trainium/)과 [AWS Inferentia](https://aws.amazon.com/machine-learning/inferentia/)를 [Amazon SageMaker](https://aws.amazon.com/sagemaker/)와 함께 사용하여 ML 워크로드를 최적화하는 방법 학습\n",
    "## 파트 2/3 - SageMaker + [Hugging Face Optimum Neuron](https://huggingface.co/docs/optimum-neuron/index)을 사용하여 Trainum 인스턴스에서 Bert 모델 미세 조정하기\n",
    "\n",
    "**SageMaker studio 커널: PyTorch 1.13 Python 3.9 CPU - ml.t3.medium** \n",
    "\n",
    "이 튜토리얼에서는 [HF Optimum Neuron](https://huggingface.co/docs/optimum-neuron/index)을 사용하여 [trn1 인스턴스](https://aws.amazon.com/ec2/instance-types/trn1/)에서 SageMaker로 미세 조정 작업을 시작하는 방법을 배우게 됩니다. HF Optimum Neuron은 학습 스크립트를 단순화하고 ML 개발자가 다양한 시나리오에서 재사용할 수 있는 이식 가능한 코드를 만들 수 있도록 도와주는 프레임워크입니다. 예를 들어 다양한 모델, 다양한 작업, 분산 학습(데이터 병렬, 텐서 병렬 등)에 활용할 수 있습니다. 또한 Optimum Neuron은 모델을 컴파일하고 AWS Inferentia에 배포하는 데 도움을 줍니다(이 튜토리얼의 3부에서 자세히 알아보세요).\n",
    "\n",
    "섹션 02에서는 Optimum Neuron API에서 메타데이터를 추출하고 현재 테스트/지원되는 모델이 포함된 테이블을 렌더링하는 방법을 볼 수 있습니다(목록에 없는 유사한 모델도 호환될 수 있지만 직접 확인해야 합니다). 이 테이블은 어떤 모델을 선택하고 간단한 방식으로 미세 조정할 수 있는지 이해하는 데 중요합니다. 그러나 학습을 위해 모델을 선택하기 전에 **파트 3** 노트북에서 유사한 테이블을 확인하여 HF Optimum Neuron을 사용하여 AWS Inferentia에 배포할 수 있는 모델을 확인하세요. 이렇게 하면 엔드투엔드 솔루션을 계획하고 지금 바로 구현을 시작할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6e0aca",
   "metadata": {},
   "source": [
    "## 1) 필요한 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5592f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02d721",
   "metadata": {},
   "source": [
    "## 2) 지원되는 모델/작업\n",
    "\n",
    "이름 뒤에 **[TP]**가 있는 모델은 텐서 병렬 처리를 지원합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa07d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(\"../docs/optimum_neuron_models.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a88d21d",
   "metadata": {},
   "source": [
    "## 3) SageMaker와 HF Optimum Neuron을 사용하여 모델 미세 조정하기\n",
    "입력 이메일이 스팸인지 아닌지 예측하는 텍스트 분류기로 Bert 모델을 학습시키고 있습니다. 자신의 시나리오에 맞게 조정하려면 다음 변수만 변경하세요: **MODEL**과 **TASK**는 위 표를 참조하세요.\n",
    "  - MODEL: HF 포털에서 사용 가능한 모델의 이름. 위 표에서 원하는 \"모델 이름\"을 클릭하여 해당 특정 모델에 대한 모든 옵션을 나열합니다.\n",
    "  - TASK: 위 표에서 원하는 작업(열 이름)을 복사합니다. 선택한 모델이 해당 작업을 지원하는지 확인하세요. 그렇지 않으면 모델을 변경해야 합니다.\n",
    "\n",
    "**이 샘플을 실행하려면 Hugging Face 자격 증명과 사용자 지정 저장소가 필요합니다.** 이 구성은 모델의 캐시 파일을 저장하는 데 필요합니다. [huggingface.co](huggingface.co/)로 이동하여 필요한 경우 계정을 만드세요. 또한 **액세스 토큰**과 새 모델 저장소를 생성해야 합니다.\n",
    "\n",
    "**CUSTOM_CACHE_REPO**를 이 학습 작업을 위해 생성한 모델 저장소로 설정하세요. 예: **user-name/model-name**. 아직 캐시 저장소가 없다면 [이 페이지의 지침을 따라](https://huggingface.co/docs/optimum-neuron/guides/cache_system) 하나 만드세요. **HF_TOKEN**을 계정에서 생성한 유효한 Hugging Face 액세스 토큰으로 설정하세요.\n",
    "\n",
    "**HF_CACHE_REPO**와 **HF_TOKEN**을 설정하지 않으면 학습 작업을 호출할 때마다 모델이 다시 컴파일되어 시간이 소요됩니다. 이 단계를 최적화하기 위해 캐시 메커니즘을 사용하는 것이 **매우** 권장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d44da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Click on the \"model name\" in the table above to visualize which options of models you have to fine-tune\n",
    "# i.e: If you click on bert, bert-base-uncased is an available option to select\n",
    "MODEL=\"bert-base-uncased\"\n",
    "TASK=\"SequenceClassification\"\n",
    "HF_CACHE_REPO=\"aws-neuron/optimum-neuron-cache\"\n",
    "HF_TOKEN=None\n",
    "assert len(MODEL)>0, \"Please, use the table above to define a valid model name\"\n",
    "assert len(TASK)>0, \"Please, use the table above to define a valid model task\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70993ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "print(sagemaker.__version__)\n",
    "if not sagemaker.__version__ >= \"2.146.0\": print(\"You need to upgrade or restart the kernel if you already upgraded\")\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sess.default_bucket()\n",
    "region = sess.boto_region_name\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "if not os.path.isdir('src'): os.makedirs('src', exist_ok=True)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {bucket}\")\n",
    "print(f\"sagemaker session region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e903b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1) SageMaker에서 호출할 학습 스크립트\n",
    "\n",
    "이 학습 스크립트는 프로세스를 단순화하기 위해 HF Optimum Neuron API를 사용합니다. [여기에서 자세히 알아볼 수 있습니다](https://huggingface.co/docs/optimum-neuron/quickstart). 이 스크립트는 학습 작업을 준비하고 모델을 빠르게 미세 조정하는 방법을 보여주기 위한 것입니다. 필요에 따라 이 스크립트를 조정/수정해야 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654a804c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pygmentize src/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbfad6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pygmentize src/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a8cc98",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2) SageMaker Estimator 정의하기\n",
    "이 객체는 학습 작업을 구성하고 필요한 하이퍼파라미터 및 기타 구성 설정을 설정하는 데 도움이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e36c66e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\", # Specify your train script\n",
    "    source_dir=\"src\",\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.trn1.2xlarge',\n",
    "    disable_profiler=True,\n",
    "    output_path=f\"s3://{bucket}/output\",\n",
    "    image_uri=f\"763104351884.dkr.ecr.{region}.amazonaws.com/pytorch-training-neuronx:1.13.1-neuronx-py310-sdk2.18.0-ubuntu20.04\",\n",
    "    \n",
    "    # Parameters required to enable checkpointing\n",
    "    # This is necessary for caching XLA HLO files and reduce training time next time    \n",
    "    checkpoint_s3_uri=f\"s3://{bucket}/checkpoints/{MODEL}\",\n",
    "    volume_size = 512,\n",
    "    distribution={\n",
    "        \"torch_distributed\": {\n",
    "            \"enabled\": True\n",
    "        }\n",
    "    },\n",
    "    environment={\n",
    "        # Uncomment the following line to precompile the cache files\n",
    "        # \"RUN_NEURON_PARALLEL_COMPILE\": \"1\"\n",
    "        \"OMP_NUM_THREADS\": \"1\",\n",
    "        \"FI_EFA_FORK_SAFE\": \"1\",        \n",
    "        \"NEURON_RT_STOCHASTIC_ROUNDING_EN\": \"1\",        \n",
    "        \"MALLOC_ARENA_MAX\":\"80\", # required to avoid OOM\n",
    "\n",
    "        # Uncomment the following line if you defined a HF HUB cache repo\n",
    "        \"CUSTOM_CACHE_REPO\": HF_CACHE_REPO\n",
    "    },\n",
    "    hyperparameters={\n",
    "        \"model_id\": MODEL,\n",
    "        \"task\": TASK,        \n",
    "        \"bf16\": True,\n",
    "        \"zero_1\": True,\n",
    "        \n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"epochs\": 1,\n",
    "        \"train_batch_size\": 4,\n",
    "        \"eval_batch_size\": 4,\n",
    "        \"max_sen_len\": 256, # this needs to be aligned with the sentence len used in the data preparation\n",
    "\n",
    "        # Uncomment this line if you have defined a valid HF_TOKEN\n",
    "        #\"hf_token\": HF_TOKEN,\n",
    "        \n",
    "        # Uncomment and configure the following line to enable TP\n",
    "        #\"tensor_parallel_size\": 8,        \n",
    "    },\n",
    "    metric_definitions=[        \n",
    "        {\"Name\": \"eval_loss\", \"Regex\": \".eval_loss.:\\S*(.*?),\"},\n",
    "        {\"Name\": \"train_loss\", \"Regex\": \"'loss.:\\S*(.*?),\"},\n",
    "        {\"Name\": \"it_per_sec\", \"Regex\": \",\\S*(.*?)it.s.\"},\n",
    "    ]\n",
    ")\n",
    "#if not HF_TOKEN is None and len(HF_TOKEN) > 0:\n",
    "    \n",
    "estimator.framework_version = '1.13.1' # workround when using image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500ec96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_uri=f\"s3://{bucket}/datasets/spam/train\"\n",
    "eval_uri=f\"s3://{bucket}/datasets/spam/eval\"\n",
    "print(f\"{train_uri}\\n{eval_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076bb8bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.fit({\"train\": train_uri, \"eval\": eval_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1804070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"training_job_name.txt\", \"w\") as f:\n",
    "    f.write(estimator._current_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c91ab2",
   "metadata": {},
   "source": [
    "## 4) 이제 모델을 배포할 시간입니다\n",
    "\n",
    "[Inf2에서의 배포/추론 노트북 열기](03_ModelInference.ipynb)  \n",
    "[Inf1에서의 배포/추론 노트북 열기](03_ModelInferenceInf1.ipynb)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
