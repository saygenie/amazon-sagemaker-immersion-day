{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd78f11b",
   "metadata": {},
   "source": [
    "# Amazon SageMaker XGBoost를 활용한 다이렉트 마케팅 타겟팅\n",
    "_**불균형 클래스를 가진 이진 예측 문제: 그래디언트 부스티드 트리를 활용한 지도 학습**_\n",
    "\n",
    "---\n",
    "\n",
    "## 배경\n",
    "우편, 이메일, 전화 등을 통한 다이렉트 마케팅은 고객을 확보하기 위한 일반적인 전략입니다. 자원과 고객의 관심이 제한되어 있기 때문에, 특정 제안에 반응할 가능성이 높은 잠재 고객 하위 집단만을 대상으로 하는 것이 목표입니다. 인구통계, 과거 상호작용, 환경적 요소와 같은 쉽게 얻을 수 있는 정보를 기반으로 잠재 고객을 예측하는 것은 일반적인 머신 러닝 문제입니다.\n",
    "\n",
    "이 노트북은 한 번 이상의 전화 통화 후 고객이 은행의 정기 예금에 가입할지 여부를 예측하는 예제 문제를 제시합니다. 단계는 다음과 같습니다:\n",
    "\n",
    "* Amazon SageMaker 노트북 준비하기\n",
    "* 인터넷에서 Amazon SageMaker로 데이터 다운로드하기\n",
    "* Amazon SageMaker 알고리즘에 공급할 수 있도록 데이터 조사 및 변환하기\n",
    "* 그래디언트 부스팅 알고리즘을 사용하여 모델 추정하기\n",
    "* 모델의 효과성 평가하기\n",
    "* 지속적인 예측을 위한 모델 설정하기\n",
    "\n",
    "---\n",
    "\n",
    "## 준비\n",
    "\n",
    "_이 노트북은 ml.m4.xlarge 노트북 인스턴스에서 생성되고 테스트되었습니다._\n",
    "\n",
    "다음 사항을 지정하는 것부터 시작하겠습니다:\n",
    "\n",
    "- 훈련 및 모델 데이터에 사용할 S3 버킷과 접두사. 이는 노트북 인스턴스, 훈련 및 호스팅과 동일한 리전에 있어야 합니다.\n",
    "- 훈련 및 호스팅에 데이터 접근 권한을 부여하는 데 사용되는 IAM 역할 ARN. 이를 생성하는 방법은 문서를 참조하세요. 노트북 인스턴스, 훈련 및/또는 호스팅에 둘 이상의 역할이 필요한 경우, boto 정규식을 적절한 전체 IAM 역할 ARN 문자열로 대체하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71aca5e",
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "# cell 01\n",
    "import sagemaker\n",
    "bucket=sagemaker.Session().default_bucket()\n",
    "prefix = 'sagemaker/DEMO-xgboost-dm'\n",
    " \n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d41a4f6",
   "metadata": {},
   "source": [
    "이제 분석 전반에 걸쳐 사용할 Python 라이브러리들을 가져오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 02\n",
    "import numpy as np                                # For matrix operations and numerical processing\n",
    "import pandas as pd                               # For munging tabular data\n",
    "import matplotlib.pyplot as plt                   # For charts and visualizations\n",
    "from IPython.display import Image                 # For displaying images in the notebook\n",
    "from IPython.display import display               # For displaying outputs in the notebook\n",
    "from time import gmtime, strftime                 # For labeling SageMaker models, endpoints, etc.\n",
    "import sys                                        # For writing outputs to notebook\n",
    "import math                                       # For ceiling function\n",
    "import json                                       # For parsing hosting outputs\n",
    "import os                                         # For manipulating filepath names\n",
    "import sagemaker \n",
    "import zipfile     # Amazon SageMaker's Python SDK provides many helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e6b97e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 데이터\n",
    "[다이렉트 마케팅 데이터셋](https://sagemaker-sample-data-us-west-2.s3-us-west-2.amazonaws.com/autopilot/direct_marketing/bank-additional.zip)을 샘플 데이터 s3 버킷에서 다운로드하여 시작하겠습니다.\n",
    "\n",
    "\\[Moro et al., 2014\\] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db49c8ea",
   "metadata": {},
   "source": [
    "이제 이것을 Pandas 데이터 프레임으로 읽어서 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f846c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 04\n",
    "data = pd.read_csv('./bank-additional/bank-additional-full.csv')\n",
    "pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 20)         # Keep the output on one page\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a83dea",
   "metadata": {},
   "source": [
    "이를 SageMaker Processing으로 처리하기 위해 S3에 네이티브하게 저장하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 05\n",
    "from sagemaker import Session\n",
    "\n",
    "sess = Session()\n",
    "input_source = sess.upload_data('./bank-additional/bank-additional-full.csv', bucket=bucket, key_prefix=f'{prefix}/input_data')\n",
    "input_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158b7edc",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Processing을 이용한 특성 공학\n",
    "\n",
    "Amazon SageMaker Processing을 사용하면 Amazon SageMaker에서 데이터 전처리 또는 후처리, 특성 공학, 데이터 검증 또는 모델 평가 워크로드를 위한 단계를 실행할 수 있습니다. Processing 작업은 Amazon S3에서 입력으로 데이터를 받아 출력을 Amazon S3에 저장합니다.\n",
    "\n",
    "![processing](https://sagemaker.readthedocs.io/en/stable/_images/amazon_sagemaker_processing_image1.png)\n",
    "\n",
    "여기서는 데이터셋을 가져와 SageMaker Processing으로 변환하겠습니다. SageMaker Processing은 노트북 서버를 실행하는 인스턴스와 별도로 SageMaker가 관리하는 클러스터에서 테라바이트 규모의 데이터를 처리하는 데 사용할 수 있습니다. 일반적인 SageMaker 워크플로우에서 노트북은 프로토타이핑에만 사용되며 비교적 저렴하고 성능이 낮은 인스턴스에서 실행할 수 있는 반면, 처리, 훈련 및 모델 호스팅 작업은 별도의 더 강력한 SageMaker 관리 인스턴스에서 실행됩니다. SageMaker Processing은 Scikit-learn을 위한 기본 지원과 함께 Bring Your Own Container 옵션을 제공하므로 다양한 데이터 변환 기술과 작업에 사용할 수 있습니다.\n",
    "\n",
    "SageMaker Processing을 사용하려면 아래와 같이 Python 데이터 전처리 스크립트를 제공하기만 하면 됩니다. 이 예제에서는 데이터 처리를 위한 많은 일반적인 함수가 포함된 SageMaker 사전 구축된 Scikit-learn 컨테이너를 사용하고 있습니다. 실행할 수 있는 코드와 작업 유형에는 거의 제한이 없으며, 최소한의 계약만 있습니다: 입력 및 출력 데이터는 지정된 디렉토리에 배치되어야 합니다. 이렇게 하면 SageMaker Processing이 자동으로 S3에서 입력 데이터를 로드하고 작업이 완료되면 변환된 데이터를 S3에 다시 업로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf0c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocessing.py\n",
    "# cell 06\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "def _parse_args():\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    # model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\n",
    "    parser.add_argument('--filepath', type=str, default='/opt/ml/processing/input/')\n",
    "    parser.add_argument('--filename', type=str, default='bank-additional-full.csv')\n",
    "    parser.add_argument('--outputpath', type=str, default='/opt/ml/processing/output/')\n",
    "    parser.add_argument('--categorical_features', type=str, default='y, job, marital, education, default, housing, loan, contact, month, day_of_week, poutcome')\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # Process arguments\n",
    "    args, _ = _parse_args()\n",
    "    # Load data\n",
    "    df = pd.read_csv(os.path.join(args.filepath, args.filename))\n",
    "    # Change the value . into _\n",
    "    df = df.replace(regex=r'\\.', value='_')\n",
    "    df = df.replace(regex=r'\\_$', value='')\n",
    "    # Add two new indicators\n",
    "    df[\"no_previous_contact\"] = (df[\"pdays\"] == 999).astype(int)\n",
    "    df[\"not_working\"] = df[\"job\"].isin([\"student\", \"retired\", \"unemployed\"]).astype(int)\n",
    "    df = df.drop(['duration', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'], axis=1)\n",
    "    # Encode the categorical features\n",
    "    df = pd.get_dummies(df)\n",
    "    # Train, test, validation split\n",
    "    train_data, validation_data, test_data = np.split(df.sample(frac=1, random_state=42), [int(0.7 * len(df)), int(0.9 * len(df))])   # Randomly sort the data then split out first 70%, second 20%, and last 10%\n",
    "    # Local store\n",
    "    pd.concat([train_data['y_yes'], train_data.drop(['y_yes','y_no'], axis=1)], axis=1).to_csv(os.path.join(args.outputpath, 'train/train.csv'), index=False, header=False)\n",
    "    pd.concat([validation_data['y_yes'], validation_data.drop(['y_yes','y_no'], axis=1)], axis=1).to_csv(os.path.join(args.outputpath, 'validation/validation.csv'), index=False, header=False)\n",
    "    test_data['y_yes'].to_csv(os.path.join(args.outputpath, 'test/test_y.csv'), index=False, header=False)\n",
    "    test_data.drop(['y_yes','y_no'], axis=1).to_csv(os.path.join(args.outputpath, 'test/test_x.csv'), index=False, header=False)\n",
    "    print(\"## Processing complete. Exiting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb4b171",
   "metadata": {},
   "source": [
    "SageMaker Processing 작업을 시작하기 전에, `SKLearnProcessor` 객체를 인스턴스화합니다. 이 객체를 통해 작업에 사용할 인스턴스 유형과 인스턴스 수를 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c662453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 07\n",
    "train_path = f\"s3://{bucket}/{prefix}/train\"\n",
    "validation_path = f\"s3://{bucket}/{prefix}/validation\"\n",
    "test_path = f\"s3://{bucket}/{prefix}/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa5dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 08\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=get_execution_role(),\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1, \n",
    "    base_job_name='sm-immday-skprocessing'\n",
    ")\n",
    "\n",
    "sklearn_processor.run(\n",
    "    code='preprocessing.py',\n",
    "    # arguments = ['arg1', 'arg2'],\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=input_source, \n",
    "            destination=\"/opt/ml/processing/input\",\n",
    "            s3_input_mode=\"File\",\n",
    "            s3_data_distribution_type=\"ShardedByS3Key\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train_data\", \n",
    "            source=\"/opt/ml/processing/output/train\",\n",
    "            destination=train_path,\n",
    "        ),\n",
    "        ProcessingOutput(output_name=\"validation_data\", source=\"/opt/ml/processing/output/validation\", destination=validation_path),\n",
    "        ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/output/test\", destination=test_path),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7221443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 09\n",
    "!aws s3 ls $train_path/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8318d26",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 실습 1 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0bbd6a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 훈련\n",
    "이제 대부분의 특성들이 왜곡된 분포를 가지고 있고, 일부는 서로 높은 상관관계가 있으며, 일부는 목표 변수와 비선형 관계를 가지고 있다는 것을 알게 되었습니다. 또한, 미래의 잠재 고객을 타겟팅하기 위해서는 왜 그 잠재 고객이 타겟팅되었는지 설명하는 것보다 좋은 예측 정확도가 선호됩니다. 이러한 측면들을 종합적으로 고려할 때, 그래디언트 부스팅 트리는 좋은 후보 알고리즘이 됩니다.\n",
    "\n",
    "알고리즘을 이해하는 데 여러 복잡한 부분이 있지만, 높은 수준에서 그래디언트 부스팅 트리는 이전 모델의 약점을 해결하려고 시도하는 많은 간단한 모델의 예측을 결합하여 작동합니다. 이렇게 함으로써 간단한 모델의 집합이 실제로 크고 복잡한 모델보다 더 나은 성능을 발휘할 수 있습니다. 다른 Amazon SageMaker 노트북에서는 그래디언트 부스팅 트리와 유사한 알고리즘과의 차이점에 대해 더 자세히 설명합니다.\n",
    "\n",
    "`xgboost`는 그래디언트 부스팅 트리를 위한 매우 인기 있는 오픈 소스 패키지입니다. 이는 계산적으로 강력하고, 기능이 완전하며, 많은 머신 러닝 대회에서 성공적으로 사용되었습니다. Amazon SageMaker의 관리형 분산 훈련 프레임워크를 사용하여 간단한 `xgboost` 모델부터 시작해 보겠습니다.\n",
    "\n",
    "먼저 Amazon SageMaker의 XGBoost 구현을 위한 ECR 컨테이너 위치를 지정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ac12d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 10\n",
    "container = sagemaker.image_uris.retrieve(region=boto3.Session().region_name, framework='xgboost', version='latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0acdb7",
   "metadata": {},
   "source": [
    "그런 다음, CSV 파일 형식으로 훈련하고 있으므로, 훈련 함수가 S3의 파일을 가리키는 포인터로 사용할 수 있는 `s3_input`을 생성하겠습니다. 이는 또한 콘텐츠 타입이 CSV임을 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e021c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 11\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_path.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=validation_path.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37138b9d",
   "metadata": {},
   "source": [
    "먼저 estimator에 훈련 매개변수를 지정해야 합니다. 여기에는 다음이 포함됩니다:\n",
    "1. `xgboost` 알고리즘 컨테이너\n",
    "1. 사용할 IAM 역할\n",
    "1. 훈련 인스턴스 유형 및 수량\n",
    "1. 출력 데이터를 위한 S3 위치\n",
    "1. 알고리즘 하이퍼파라미터\n",
    "\n",
    "그리고 다음을 지정하는 `.fit()` 함수:\n",
    "1. 출력 데이터를 위한 S3 위치. 이 경우 훈련 세트와 검증 세트가 모두 전달됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81547ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 12\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60826363",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 호스팅\n",
    "이제 `xgboost` 알고리즘을 데이터로 학습시켰으니, 실시간 엔드포인트 뒤에 호스팅되는 모델을 배포해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32191c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 13\n",
    "xgb_predictor = xgb.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6672a3c2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 평가\n",
    "머신 러닝 모델의 성능을 비교하는 방법은 많지만, 실제 값과 예측 값을 단순히 비교하는 것부터 시작해 보겠습니다. 이 경우, 우리는 고객이 정기 예금에 가입했는지(`1`) 아닌지(`0`)를 예측하는 것이므로 간단한 혼동 행렬(confusion matrix)이 생성됩니다.\n",
    "\n",
    "먼저 우리의 엔드포인트로 데이터를 어떻게 전달하고 결과를 받을지 결정해야 합니다. 현재 데이터는 노트북 인스턴스의 메모리에 NumPy 배열로 저장되어 있습니다. HTTP POST 요청으로 이를 전송하기 위해, CSV 문자열로 직렬화한 다음 결과 CSV를 디코딩하겠습니다.\n",
    "\n",
    "*참고: CSV 형식으로 추론할 때, SageMaker XGBoost는 데이터에 타겟 변수가 포함되지 않아야 합니다.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4b2d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 14\n",
    "xgb_predictor.serializer = sagemaker.serializers.CSVSerializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c0c37",
   "metadata": {},
   "source": [
    "이제 간단한 함수를 사용하여 다음을 수행하겠습니다:\n",
    "1. 테스트 데이터셋을 반복합니다\n",
    "2. 데이터셋을 행 단위의 미니 배치로 분할합니다\n",
    "3. 이러한 미니 배치를 CSV 문자열 페이로드로 변환합니다(먼저 데이터셋에서 타겟 변수를 제거합니다)\n",
    "4. XGBoost 엔드포인트를 호출하여 미니 배치 예측을 검색합니다\n",
    "5. 예측을 수집하고 모델이 제공하는 CSV 출력을 NumPy 배열로 변환합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f627a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 15\n",
    "!aws s3 cp $test_path/test_x.csv /tmp/test_x.csv\n",
    "!aws s3 cp $test_path/test_y.csv /tmp/test_y.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f82adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 16\n",
    "def predict(data, predictor, rows=500 ):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "test_x = pd.read_csv('/tmp/test_x.csv', names=[f'{i}' for i in range(59)])\n",
    "test_y = pd.read_csv('/tmp/test_y.csv', names=['y'])\n",
    "predictions = predict(test_x.to_numpy(), xgb_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef14d97",
   "metadata": {},
   "source": [
    "이제 예측값과 실제값을 비교하여 혼동 행렬을 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2211338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 17\n",
    "pd.crosstab(index=test_y['y'].values, columns=np.round(predictions), rownames=['actuals'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba45ec8e",
   "metadata": {},
   "source": [
    "따라서 약 4000명의 잠재 고객 중에서 우리는 136명이 구독할 것이라고 예측했고, 그 중 94명이 실제로 구독했습니다. 또한 우리가 예측하지 못했지만 실제로 구독한 고객이 389명 있었습니다. 이는 바람직하지 않지만, 모델은 이를 개선하기 위해 튜닝될 수 있고(그리고 그래야 합니다). 가장 중요한 점은 최소한의 노력으로 우리의 모델이 [여기](http://media.salford-systems.com/video/tutorial/2015/targeted_marketing.pdf)에 발표된 것과 유사한 정확도를 생성했다는 것입니다.\n",
    "\n",
    "_알고리즘의 하위 샘플에 일부 무작위 요소가 있기 때문에, 여러분의 결과는 위에 작성된 텍스트와 약간 다를 수 있습니다._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1e9af",
   "metadata": {},
   "source": [
    "### 정리\n",
    "이 노트북에서 더 이상 사용하지 않을 리소스를 삭제하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 18\n",
    "xgb_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bee43d",
   "metadata": {},
   "source": [
    "--\n",
    "## 서버리스 배포 (선택 사항)\n",
    "모델 학습 후, 모델을 엔드포인트에 배포할 수 있도록 모델 아티팩트를 가져오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f04b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup clients\n",
    "import boto3\n",
    "\n",
    "client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime = boto3.client(service_name=\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1dcfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve model data from training job\n",
    "model_artifacts = xgb.model_data\n",
    "model_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f6ca5a",
   "metadata": {},
   "source": [
    "### 모델 생성\n",
    "모델 아티팩트, 컨테이너 이미지 URI, 컨테이너용 환경 변수(해당되는 경우), 모델 이름 및 SageMaker IAM 역할을 제공하여 모델을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9657076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = \"xgboost-serverless\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Model name: \" + model_name)\n",
    "\n",
    "# dummy environment variables\n",
    "byo_container_env_vars = {\"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\", \"SOME_ENV_VAR\": \"myEnvVar\"}\n",
    "\n",
    "create_model_response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            \"Image\": container,\n",
    "            \"Mode\": \"SingleModel\",\n",
    "            \"ModelDataUrl\": model_artifacts,\n",
    "            \"Environment\": byo_container_env_vars,\n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6081f443",
   "metadata": {},
   "source": [
    "### 엔드포인트 구성 생성\n",
    "여기서 엔드포인트에 대한 서버리스 구성을 조정할 수 있습니다. 단일 엔드포인트에 대한 현재 최대 동시 호출 수인 MaxConcurrency는 1에서 200 사이의 값이 될 수 있으며, MemorySize는 다음 중 하나가 될 수 있습니다: 1024 MB, 2048 MB, 3072 MB, 4096 MB, 5120 MB 또는 6144 MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_epc_name = \"xgboost-serverless-epc\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=xgboost_epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"byoVariant\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"ServerlessConfig\": {\n",
    "                \"MemorySizeInMB\": 4096,\n",
    "                \"MaxConcurrency\": 1,\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e901397",
   "metadata": {},
   "source": [
    "### 서버리스 엔드포인트 생성\n",
    "이제 엔드포인트 구성이 완료되었으므로, 서버리스 엔드포인트를 생성하고 모델을 배포할 수 있습니다. 엔드포인트를 생성할 때, 엔드포인트 구성의 이름과 새 엔드포인트의 이름을 제공하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"xgboost-serverless-ep\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=xgboost_epc_name,\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397ea44b",
   "metadata": {},
   "source": [
    "엔드포인트 상태가 InService가 될 때까지 기다린 후 엔드포인트를 호출하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b92e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for endpoint to reach a terminal state (InService) using describe endpoint\n",
    "import time\n",
    "\n",
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "\n",
    "describe_endpoint_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8357c469",
   "metadata": {},
   "source": [
    "### 엔드포인트 호출\n",
    "엔드포인트에 요청을 보내 호출합니다. 다음은 공개 Abalone 데이터셋에서 다운로드한 CSV 파일에서 가져온 샘플 데이터 포인트입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f4719",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = \"29,2,999,0,1,0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0\"\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=payload,\n",
    "    ContentType=\"text/csv\",\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd0a168",
   "metadata": {},
   "source": [
    "### 정리\n",
    "이 노트북에서 생성한 리소스 중 더 이상 사용하지 않을 리소스를 삭제하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512262f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_model(ModelName=model_name)\n",
    "client.delete_endpoint_config(EndpointConfigName=xgboost_epc_name)\n",
    "client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a2a34a",
   "metadata": {},
   "source": [
    "## 자동 모델 튜닝 (선택 사항)\n",
    "Amazon SageMaker 자동 모델 튜닝(하이퍼파라미터 튜닝이라고도 함)은 사용자가 지정한 알고리즘과 하이퍼파라미터 범위를 사용하여 데이터셋에서 여러 훈련 작업을 실행하여 모델의 최적 버전을 찾습니다. 그런 다음 사용자가 선택한 메트릭에 따라 가장 좋은 성능을 보이는 모델을 만드는 하이퍼파라미터 값을 선택합니다.\n",
    "예를 들어, 이 마케팅 데이터셋에서 이진 분류 문제를 해결하려고 한다고 가정해 보겠습니다. 목표는 XGBoost 알고리즘 모델을 훈련하여 알고리즘의 곡선 아래 영역(auc) 메트릭을 최대화하는 것입니다. 최상의 모델을 훈련하기 위해 eta, alpha, min_child_weight 및 max_depth 하이퍼파라미터의 어떤 값을 사용해야 하는지 모릅니다. 이러한 하이퍼파라미터의 최적 값을 찾기 위해, Amazon SageMaker 하이퍼파라미터 튜닝이 선택한 목표 메트릭에 따라 가장 좋은 성능을 보이는 훈련 작업을 찾기 위해 검색할 값의 범위를 지정할 수 있습니다. 하이퍼파라미터 튜닝은 지정한 범위 내의 하이퍼파라미터 값을 사용하는 훈련 작업을 시작하고, auc가 가장 높은 훈련 작업을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 18\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "hyperparameter_ranges = {'eta': ContinuousParameter(0, 1),\n",
    "                            'min_child_weight': ContinuousParameter(1, 10),\n",
    "                            'alpha': ContinuousParameter(0, 2),\n",
    "                            'max_depth': IntegerParameter(1, 10)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9716b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 19\n",
    "objective_metric_name = 'validation:auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0654157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 20\n",
    "tuner = HyperparameterTuner(xgb,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=20,\n",
    "                            max_parallel_jobs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e53e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 21\n",
    "tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0edacc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 22\n",
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66134e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 23\n",
    "# return the best training job name\n",
    "tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 24\n",
    "#  Deploy the best trained or user specified model to an Amazon SageMaker endpoint\n",
    "tuner_predictor = tuner.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a764ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 25\n",
    "# Create a serializer\n",
    "tuner_predictor.serializer = sagemaker.serializers.CSVSerializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992d7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 26\n",
    "# Predict\n",
    "predictions = predict(test_x.to_numpy(),tuner_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16abafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 27\n",
    "# Collect predictions and convert from the CSV output our model provides into a NumPy array\n",
    "pd.crosstab(index=test_y['y'].values, columns=np.round(predictions), rownames=['actuals'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7178fb84",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 확장\n",
    "\n",
    "이 예제는 비교적 작은 데이터셋을 분석했지만, 분산 및 관리형 훈련과 실시간 모델 호스팅과 같은 Amazon SageMaker 기능을 활용했으며, 이는 훨씬 더 큰 문제에도 쉽게 적용할 수 있습니다. 예측 정확도를 더욱 향상시키기 위해 예측 임계값을 조정하여 거짓 양성과 거짓 음성의 비율을 변경하거나, 하이퍼파라미터 튜닝과 같은 기술을 탐색할 수 있습니다. 실제 시나리오에서는 수작업으로 특성 엔지니어링에 더 많은 시간을 투자하고, 초기 데이터셋에서 사용할 수 없는 고객 정보가 포함된 추가 데이터셋을 찾아볼 가능성이 높습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249567db",
   "metadata": {},
   "source": [
    "### 정리\n",
    "\n",
    "이 노트북을 모두 사용했다면, 아래 셀을 실행해주세요. 이렇게 하면 생성한 호스팅 엔드포인트가 제거되어 인스턴스가 실행된 채로 남아 요금이 발생하는 것을 방지할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26040b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 29\n",
    "tuner_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
